# Hakaton 2025 - Task 8

## О проекте

Этот проект представляет собой комплексный веб-сервис для загрузки и асинхронной обработки медицинских DICOM-снимков. Он построен на сервис-ориентированной архитектуре и включает в себя бэкенд, фронтенд и готовый к интеграции AI-модуль.

- **Бэкенд**: Написан на Django и Django REST Framework. Отвечает за API, аутентификацию, загрузку файлов, управление данными и запуск асинхронных задач.
- **Фронтенд**: Написан на Next.js (React). Предоставляет красивый и анимированный интерфейс для загрузки файлов.
- **AI-сервис**: Отдельный FastAPI-сервис, готовый для встраивания PyTorch-модели. Он принимает путь к файлу и возвращает результаты анализа.

### Ключевые технологии

- **Бэкенд**: Python, Django, DRF, Celery, PostgreSQL, Redis, `openpyxl`.
- **AI**: FastAPI, PyTorch, Pydicom, `opencv-python`.
- **Фронтенд**: TypeScript, Next.js, React, Tailwind CSS.
- **Оркестрация**: Docker, Docker Compose.

## Идеология

- **Асинхронность**: Сразу после загрузки файла, бэкенд автоматически запускает Celery-задачу. Эта задача обращается к AI-сервису, что не блокирует основной поток и обеспечивает отзывчивость системы.
- **Разделение ответственности**: Каждый компонент (Django, FastAPI, Next.js) работает в своем контейнере, взаимодействуя через API. Это упрощает разработку, тестирование и масштабирование.
- **Контейнеризация**: Весь проект полностью готов к запуску одной командой благодаря Docker Compose. Это гарантирует идентичность окружения и простоту развертывания.
- **Готовность к AI**: Архитектура полностью готова к работе с нейросетью. Celery-задача уже настроена на вызов AI-сервиса. Вам остается только дописать логику самой модели.

## Основные возможности

- **Аутентификация**: JWT-аутентификация с получением и автоматическим обновлением токенов.
- **Загрузка файлов**: Реализована по частям (чанкинг), что позволяет загружать большие файлы.
- **Автоматическая AI-обработка**: Сразу после загрузки файла запускается его обработка нейросетью.
- **API**: Предоставляются эндпоинты для просмотра результатов сканирования, срезов и DICOM-информации с гибкой системой фильтрации.
- **Экспорт в Excel**: Возможность выгрузить отчет по выбранным сканам в формате `.xlsx`.

## Быстрый запуск

**Важно**: Перед первым запуском убедитесь, что вы скачали веса для AI-модели с помощью Git LFS:
```bash
git lfs pull
```

## Запуск с помощью Docker

Проект полностью контейнеризирован, что обеспечивает простоту запуска и консистентность окружения.

### Полный запуск проекта

Для запуска всех сервисов одновременно (бэкенд, фронтенд, AI, БД, Redis, Celery) выполните одну команду из корня проекта:

```bash
# Сборка образов и запуск контейнеров в фоновом режиме
docker-compose up --build -d
```

После этого все сервисы будут запущены. Чтобы остановить их, выполните:
```bash
docker-compose down
```

### Запуск отдельных сервисов

Вы можете запускать только определенные сервисы. Например, чтобы запустить только бэкенд и его зависимости (БД, Redis):

```bash
docker-compose up --build -d hk_backend hk_db hk_redis hk_celery_worker
```

### Просмотр логов

Для просмотра логов всех запущенных контейнеров в реальном времени:
```bash
docker-compose logs -f
```

Для логов конкретного сервиса (например, бэкенда):
```bash
docker-compose logs -f hk_backend
```

## Доступ к сервисам

- **Фронтенд (интерфейс для загрузки)**: [http://localhost:3000](http://localhost:3000)
- **Бэкенд API (Swagger)**: [http://localhost:8001/api/schema/docs/](http://localhost:8001/api/schema/docs/)
- **Админ-панель Django**: [http://localhost:8001/admin/](http://localhost:8001/admin/) (логин: `admin`, пароль: `admin`)
- **AI-сервис**: доступен внутри Docker-сети по адресу `http://hk_ai:8000`

### Локальная разработка

При необходимости можно переключать бэкенд на использование локальной базы данных SQLite вместо PostgreSQL в Docker.

1.  Создайте файл `.env` в директории `backend/`.
2.  Добавьте в него строку `DB_LOCAL=True`.
3.  Перезапустите контейнеры.